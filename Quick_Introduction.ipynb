{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick introduction to look for how to look at the data and what the first task will require. \n",
    "\n",
    "SDSS J114404.76+052951.77 is a white dwarf. https://ui.adsabs.harvard.edu/abs/2015ApJ...810L..17G/abstract suggested that it had a gas disc around it due to emission from Calcium. We found that the emission is actually due to an orbiting companion, probably a brown dwarf. Your task is to measure the orbital period of the system.  \n",
    "\n",
    "Some reading material on similar systems here https://ui.adsabs.harvard.edu/public-libraries/qIO0Ze9fQzGnpI49Ywtv4A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy.io.fits as fits\n",
    "import os\n",
    "import glob\n",
    "import natsort\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import rcParams\n",
    "rcParams[\"figure.figsize\"] = (14, 5)\n",
    "rcParams[\"font.size\"] = 20\n",
    "\n",
    "#fitting the emission lines\n",
    "from astropy.modeling import models, fitting\n",
    "from astropy import constants as const\n",
    "from astropy import units as u\n",
    "import pandas as pd\n",
    "from astropy.convolution import convolve, Box1DKernel\n",
    "from scipy.signal import find_peaks\n",
    "from astropy.table import Table\n",
    "from astropy.io import fits\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating through all of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/linaflorez/Desktop/UT_TAURUS/WDJ114404.76+052951.77/\" #note the / on the end\n",
    "print(os.listdir(path))\n",
    "vispath = path + 'VIS_notell/'\n",
    "sp_csv = natsort.natsorted(glob.glob(vispath+'*TAC.csv')) #makes an array containing the path to all csv files. Note the TAC as I didn't want to include the merged spectrum\n",
    "sp_fits = natsort.natsorted(glob.glob(vispath+'*TAC.fits')) #makes an array containing the path to all csv files. Note the TAC as I didn't want to include the merged spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "path = \"/Users/linaflorez/Desktop/UT_TAURUS/WDJ114404.76+052951.77/\" #note the / on the end\n",
    "print(os.listdir(path))\n",
    "vispath = path + 'VIS_notell/'\n",
    "sp_csv = natsort.natsorted(glob.glob(vispath+'*TAC.csv')) #makes an array containing the path to all csv files. Note the TAC as I didn't want to include the merged spectrum\n",
    "sp_fits = natsort.natsorted(glob.glob(vispath+'*TAC.fits')) #makes an array containing the path to all csv files. Note the TAC as I didn't want to include the merged spectrum\n",
    "peak_wavelength_range = [(8494,8498),(8538,8542.5),(8657.75,8662.5)]\n",
    "wavelength_range = (8450,8700)\n",
    "NIR_wavelengths = [8498.02, 8542.09, 8662.14]\n",
    "num_peaks = 3\n",
    "\n",
    "def fitting_emission_lines(w,f,num_peaks,wavelength_range, file_num):\n",
    "    \n",
    "    ################################################################\n",
    "    #### MASKING WAVELENGTH & FLUX TO ONLY \n",
    "    #### INCLUDE THE PLOTTED SECTION FROM ABOVE\n",
    "    ################################################################\n",
    "    overall_min_range, overall_max_range = wavelength_range[0], wavelength_range[1]\n",
    "    general_mask = (w > overall_min_range) & (w < overall_max_range)\n",
    "    w, f = w[general_mask], f[general_mask]\n",
    "    \n",
    "    \n",
    "    ################################################################\n",
    "    #### FITTING THE CONTINUUM USING ASTROPY, FOLLOWED BY \n",
    "    #### NORMALIZING & SMOOTHING OUT THE FLUX ACCORDINGLY\n",
    "    ################################################################\n",
    "    fitter = fitting.LinearLSQFitter()\n",
    "    n_init = models.Polynomial1D(1)\n",
    "    n_fit = fitter(n_init, w, f)\n",
    "    f = f / n_fit(w)\n",
    "    f = convolve(f, Box1DKernel(10))\n",
    "    \n",
    "    \n",
    "    ################################################################\n",
    "    #### FINDING THE PEAKS USING SCIPY\n",
    "    ################################################################\n",
    "    peaks, properties = find_peaks(f, height = 0.25, distance = 40)\n",
    "    w_peaks = w[peaks][(np.argpartition(f[peaks], -3)[-3:])]\n",
    "    f_peaks = f[peaks][(np.argpartition(f[peaks], -3)[-3:])]\n",
    "\n",
    "\n",
    "    w_sorted = np.sort(w_peaks)\n",
    "    detection_test = np.zeros(num_peaks)\n",
    "    for i in range(num_peaks):\n",
    "        detection_test[i] = NIR_wavelengths[i] - w_sorted[i]\n",
    "\n",
    "    sign = np.sign(detection_test)\n",
    "    if ((all(elements == 1 for elements in sign)) or (all(elements == -1 for elements in sign))) and ((all(abs(values) <= 30 for values in detection_test))):\n",
    "        detection = \"Yes\" \n",
    "    else:\n",
    "        detection = \"No\" \n",
    "\n",
    "        \n",
    "    ################################################################\n",
    "    #### FITTING THE PEAKS USING ASTROPY\n",
    "    ################################################################\n",
    "    for i in range(num_peaks):\n",
    "        if i == 0:\n",
    "            model = models.Const1D(1.0)+models.Gaussian1D(1.0, w_peaks[i], 1)\n",
    "        else:   \n",
    "            model = model + models.Gaussian1D(1.0, w_peaks[i], 1)\n",
    "        \n",
    "    ################################################################\n",
    "    #### MAKING THE FITS\n",
    "    ################################################################\n",
    "    #gg_init = models.Const1D(1.0)\n",
    "    #g_init = gg_init + model\n",
    "    fitter = fitting.LevMarLSQFitter()\n",
    "    g_peak_norm = fitter(model, w, f) \n",
    "    fit_e = fitter.fit_info[\"param_cov\"]\n",
    "\n",
    "    ################################################################\n",
    "    #### PLOTTING NORMALIZED DATA\n",
    "    ################################################################\n",
    "    # Plot the data with the best-fit model\n",
    "    plt.style.use(\"dark_background\")\n",
    "    plt.figure(num=None, figsize=(18, 6),facecolor='w', edgecolor='k')\n",
    "    plt.plot(w, f, \"w\", markersize = 10, label = \"Normalized Flux\")\n",
    "    \n",
    "    \n",
    "    ################################################################\n",
    "    #### PLOTTING FITS DATA\n",
    "    ################################################################\n",
    "    plt.axvline(NIR_wavelengths[0], color = \"cyan\", label = \"NIR ${\\lambda}$ values\")\n",
    "    plt.axvline(NIR_wavelengths[1], color = \"cyan\")\n",
    "    plt.axvline(NIR_wavelengths[2], color = \"cyan\")\n",
    "#     plt.plot(w[peaks],f[peaks],\"bo\", label = \"scipy (each peak)\")\n",
    "    plt.plot(w, g_peak_norm(w),\"m--\", label = \"Gaussian Fit\")\n",
    "#     plt.plot(w, n_fit(w)+1, \"m.\", label = \"Continuum Fit\")\n",
    "    plt.xlabel(\"Wavelength (${\\AA}$)\", weight = \"bold\", size = 15)\n",
    "    plt.ylabel(\"Flux\", weight = \"bold\", size = 15)\n",
    "    plt.legend(loc = \"best\", prop = {\"size\" : 15}, frameon = False)\n",
    "    plt.tick_params(axis= \"both\", which = \"major\", labelsize = 13)\n",
    "    plt.xlim(overall_min_range, overall_max_range)\n",
    "    plt.xlim(wavelength_range[0],wavelength_range[1])\n",
    "    plt.ylim(-0.1,2)\n",
    "    plt.savefig(\"/Users/linaflorez/Desktop/UT_TAURUS/Plots/BLAH/%i.pdf\" % (file_num), transparent = True, dpi = 300, quality = 95)\n",
    "    plt.show()\n",
    "    return g_peak_norm, detection\n",
    "\n",
    "\n",
    "def doppler_velocity_func(NIR_wavelengths,csv_path_files, fits_path_files, num_peaks,wavelength_range):\n",
    "    ################################################################\n",
    "    #### CONVERTING C TO KM/S\n",
    "    ################################################################\n",
    "    c = ((const.c).to(u.km/u.s)).value\n",
    "    \n",
    "    \n",
    "    ###############################################################\n",
    "    #### ITERATING THROUGH ALL THE CSV FILES\n",
    "    ################################################################\n",
    "    sp = csv_path_files\n",
    "    sp_f = fits_path_files\n",
    "    \n",
    "    \n",
    "    ###############################################################\n",
    "    #### STORING THE VELOCITIES\n",
    "    ################################################################    \n",
    "    tracking_file_num = []\n",
    "    vel1 = []\n",
    "    vel2 = []\n",
    "    vel3 = []\n",
    "    file_path = []\n",
    "    MJD = []\n",
    "    detections = []\n",
    "    \n",
    "    \n",
    "    for i in range(0,np.shape(sp)[0]):\n",
    "        ###############################################################\n",
    "        #### GRABBING INFO FROM CSV FILES\n",
    "        ################################################################ \n",
    "        s = sp[i]\n",
    "        file_path.append(s.split(\"VIS_notell/\",1)[1])\n",
    "        w, f, e = np.loadtxt(s, unpack=True, delimiter=',')\n",
    "        peak_values, detection = fitting_emission_lines(w,f,num_peaks, wavelength_range,i)\n",
    "\n",
    "        ###############################################################\n",
    "        #### GRABBING INFO FROM FITS FILES\n",
    "        ################################################################ \n",
    "        s_fits = sp_f[i]\n",
    "        hdulist = fits.open(s_fits)\n",
    "        hdu = hdulist[0]\n",
    "        MJD_OBS = hdu.header[\"MJD-OBS\"] #in mjd (units are days)\n",
    "        EXPTIME = hdu.header[\"EXPTIME\"] # in secs\n",
    "        time_dependence = (MJD_OBS * u.d) + (((EXPTIME/2)*u.s).to(u.d))\n",
    "        time_dependence = time_dependence.value\n",
    "        \n",
    "        ###############################################################\n",
    "        #### VALUES FROM THE NIR WEBSITE\n",
    "        ################################################################\n",
    "        NIR_wavelength_peak1 = NIR_wavelengths[0]\n",
    "        NIR_wavelength_peak2 = NIR_wavelengths[1]\n",
    "        NIR_wavelength_peak3 = NIR_wavelengths[2]\n",
    "        \n",
    "        \n",
    "        ###############################################################\n",
    "        #### WAVELENGTHS OF THE PEAKS COURTESY OF THE GAUSSIAN FITS\n",
    "        ################################################################\n",
    "        peak_w = [peak_values.mean_1.value, peak_values.mean_2.value, peak_values.mean_3.value]\n",
    "        peak_w = np.sort(peak_w)\n",
    "        peak1_fitvalue = peak_w[0]\n",
    "        peak2_fitvalue = peak_w[1]\n",
    "        peak3_fitvalue = peak_w[2]\n",
    "        \n",
    "        \n",
    "        ###############################################################\n",
    "        #### CALCULATING THE SHIFT\n",
    "        ################################################################\n",
    "        shift_peak1 = NIR_wavelength_peak1 - peak1_fitvalue\n",
    "        shift_peak2 = NIR_wavelength_peak2 - peak2_fitvalue\n",
    "        shift_peak3 = NIR_wavelength_peak3 - peak3_fitvalue\n",
    "        \n",
    "        \n",
    "        ################################################################\n",
    "        #### EQUATION FOR DOPPLER VELOCITY\n",
    "        #### SPEED OF LIGHT * (WAVELENGTH SHIFT / OG WAVELENGTH) = VELOCITY\n",
    "        ################################################################\n",
    "        d_vel_peak1 = c * (shift_peak1 / NIR_wavelength_peak1)\n",
    "        d_vel_peak2 = c * (shift_peak2 / NIR_wavelength_peak2)\n",
    "        d_vel_peak3 = c * (shift_peak3 / NIR_wavelength_peak3)\n",
    "    \n",
    "\n",
    "        ###############################################################\n",
    "        #### STORING VALUES\n",
    "        ################################################################\n",
    "        tracking_file_num.append(i)\n",
    "        vel1.append(d_vel_peak1)\n",
    "        vel2.append(d_vel_peak2)\n",
    "        vel3.append(d_vel_peak3)\n",
    "        MJD.append(time_dependence)\n",
    "        detections.append(detection)\n",
    "       \n",
    "    \n",
    "    ###############################################################\n",
    "    #### MAKING DATA TABLE\n",
    "    ################################################################\n",
    "    t = Table([tracking_file_num, vel1, vel2,vel3, detections, MJD,file_path], names=(\"File Number (sp[i])\", \"First Peak Doppler Velocity (km/s)\", \\\n",
    "                                                                       \"Second Peak Doppler Velocity (km/s)\",\"Third Peak Doppler Velocity (km/s)\",\\\n",
    "                                                                      \"Detection\", \"Time (MJD)\",\"File Path\"), meta={\"name\": \"first table\"})\n",
    "    velocities_array = (np.array([vel1,vel2,vel3])).T\n",
    "\n",
    "            \n",
    "    return t,tracking_file_num, velocities_array,MJD,detections #doppler_velocities tablein km/s\n",
    "info_table,file_num,v_array,time_array, detect_array = doppler_velocity_func(NIR_wavelengths,sp_csv,sp_fits,3,wavelength_range)\n",
    "# info_table.write(\"DopplerVelocitiesTABLE.csv\", format=\"ascii.csv\", overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then look up where they should be from the NIST database (https://physics.nist.gov/PhysRefData/ASD/lines_form.html) and measure the doppler velocity for each spectrum.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.modeling import models, fitting\n",
    "\n",
    "# Generate fake data\n",
    "np.random.seed(0)\n",
    "x = np.linspace(-5., 5., 200)\n",
    "y = 3 * np.exp(-0.5 * (x - 1.3)**2 / 0.8**2)\n",
    "y += np.random.normal(0., 0.2, x.shape)\n",
    "\n",
    "mask = [x > 0]\n",
    "# Fit the data using a Gaussian\n",
    "g_init = models.Gaussian1D(amplitude=1, mean=0, stddev=1)\n",
    "fitter = fitting.LevMarLSQFitter()\n",
    "g = fitter(g_init,x,y)\n",
    "fit_e = np.sqrt(np.diag(fitter.fit_info['param_cov']))\n",
    "\n",
    "# Plot the data with the best-fit model\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(x, y, 'ko')\n",
    "plt.plot(x, g(x), label='Gaussian')\n",
    "plt.xlabel('Position')\n",
    "plt.ylabel('Flux')\n",
    "plt.legend(loc=2)\n",
    "print(\"OG FIT VALUES: 0.04850527 0.01526921 0.01667328\")\n",
    "print(\"FIT:\",fit_e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
