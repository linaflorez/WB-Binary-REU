{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import astropy.io.fits as fits\n",
    "import os\n",
    "import glob\n",
    "import natsort\n",
    "\n",
    "#fitting the emission lines\n",
    "from astropy.modeling import models, fitting\n",
    "from astropy import constants as const\n",
    "from astropy import units as u\n",
    "import pandas as pd\n",
    "from astropy.convolution import convolve, Box1DKernel\n",
    "from scipy.signal import find_peaks\n",
    "from astropy.table import Table, Column, QTable\n",
    "from astropy.io import fits\n",
    "\n",
    "#Lomb-Scargle Periodograms\n",
    "from astropy.timeseries import LombScargle as LS\n",
    "\n",
    "#fitting the absorption lines\n",
    "from specutils.spectra import Spectrum1D\n",
    "from specutils.fitting import fit_lines\n",
    "import heapq\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitting_absorption_lines(wavelength_range, sp_csv, sp_fits, detections):\n",
    "    ################################################################\n",
    "    #### CONSTANTS\n",
    "    ################################################################\n",
    "    halpha = ((656.28 * u.nm).to(u.Angstrom)).value\n",
    "    c = ((const.c).to(u.km/u.s)).value\n",
    "\n",
    "    ################################################################\n",
    "    #### INITIALIZING BLANK ARRAYS\n",
    "    ################################################################\n",
    "    dv_a = np.zeros(np.shape(sp_csv)[0])\n",
    "    dv_e = np.zeros(np.shape(sp_csv)[0])\n",
    "    time = np.zeros(np.shape(sp_csv)[0])\n",
    "    file_path = np.zeros(np.shape(sp_csv)[0], dtype = str)\n",
    "    fit_error = np.zeros(np.shape(sp_csv)[0])\n",
    "    \n",
    "    for i, val in enumerate(detections == \"Yes\"):\n",
    "        ################################################################\n",
    "        #### GETTING DATA\n",
    "        ################################################################\n",
    "        s_fits = sp_fits[i]\n",
    "        hdulist = fits.open(s_fits)\n",
    "        hdu = hdulist[0]\n",
    "        MJD_OBS, EXPTIME = hdu.header[\"MJD-OBS\"], hdu.header[\"EXPTIME\"]\n",
    "        time[i] = ((MJD_OBS * u.d) + (((EXPTIME/2)*u.s).to(u.d))).value\n",
    "\n",
    "        s = sp_csv[i]\n",
    "        file_path = (s.split(vispath,1)[1])\n",
    "        w, f, e = np.loadtxt(s, unpack=True, delimiter=',')\n",
    "        \n",
    "        ################################################################\n",
    "        #### NORMALIZING AND SMOOTHING FLUX & ERROR\n",
    "        ################################################################\n",
    "        min_range, max_range = wavelength_range[0], wavelength_range[1]\n",
    "        fitter = fitting.LinearLSQFitter()\n",
    "        n_init = models.Polynomial1D(1)\n",
    "        range_mask = (w > min_range) & (w < max_range)\n",
    "        w, f, e = w[range_mask], f[range_mask], e[range_mask]\n",
    "        \n",
    "        cont_mask = (w > 6400)  & (w < 6500) | (w > 6690) & (w < 6700 )\n",
    "        w_cont, f_cont = w[cont_mask], f[cont_mask]\n",
    "        n_fit = fitter(n_init, w_cont, f_cont)\n",
    "        f = f / n_fit(w)\n",
    "        f = convolve(f, Box1DKernel(10))\n",
    "        \n",
    "        smoothed_err = e / n_fit(w)\n",
    "        smoothed_err = convolve(smoothed_err, Box1DKernel(10))\n",
    "        e = smoothed_err / np.sqrt(10)\n",
    "\n",
    "        ################################################################\n",
    "        #### FINDING ABSORPTION AMPLITUDE & MEAN FOR MODEL INPUT\n",
    "        ################################################################\n",
    "        mask = (w > 6555) & (w < 6573)\n",
    "        w_masked, f_masked = w[mask], f[mask]\n",
    "        a_loc = (np.diff(np.sign(np.diff(f_masked))) > 0).nonzero()[0] + 1 \n",
    "        absorption_mean = w_masked[a_loc][np.argmin(f_masked[a_loc])]\n",
    "        absorption_amplitude = f_masked[a_loc][np.argmin(f_masked[a_loc])]\n",
    "\n",
    "        ################################################################\n",
    "        #### TYING FUNCTION FOR FITS\n",
    "        ################################################################\n",
    "        def tied_function(model):\n",
    "            mean = model.mean_1.value\n",
    "            return mean\n",
    "        tied_parameters = {'mean_0': tied_function, 'mean_2': tied_function}\n",
    "\n",
    "        ################################################################\n",
    "        #### IF THERE ARE EMISSION LINES\n",
    "        ################################################################\n",
    "        if val == True:\n",
    "            peak_loc = (np.diff(np.sign(np.diff(f_masked))) < 0).nonzero()[0] + 1 \n",
    "            emission_mean = w_masked[peak_loc][np.argmax(f_masked[peak_loc])]\n",
    "            emission_amplitude = f_masked[peak_loc][np.argmax(f_masked[peak_loc])]\n",
    "            \n",
    "            ################################################################\n",
    "            #### MAKING THE MODEL\n",
    "            ################################################################\n",
    "            g1 = models.Gaussian1D(-absorption_amplitude, absorption_mean,0.5) #narrowest portion \n",
    "            g2 = models.Gaussian1D(-0.3, absorption_mean,5) #broader portion \n",
    "            g3 = models.Gaussian1D(-0.2, absorption_mean,30) #widest portion \n",
    "            g4 = models.Gaussian1D(0.2, emission_mean, 0.7) #emission line\n",
    "            model = g1 + g2 + g3 + g4 + models.Const1D(1)\n",
    "            \n",
    "            model.mean_0.tied = tied_function\n",
    "            model.mean_2.tied = tied_function\n",
    "            model.stddev_0.fixed = True\n",
    "            model.stddev_1.fixed = True\n",
    "            model.stddev_2.fixed = True\n",
    "            model.stddev_3.fixed = True\n",
    "            \n",
    "            fit = fitting.LevMarLSQFitter()\n",
    "            g = fit(model, w, f, maxiter=1000000, weights = 1/e)        \n",
    "            ################################################################\n",
    "            #### CHECKING THE EFFICACY OF THE FITS\n",
    "            ################################################################\n",
    "            plt.style.use(\"seaborn\")\n",
    "            plt.figure(num=None, figsize=(15, 9),facecolor='w', edgecolor='k')\n",
    "            plt.title(\"From File Number: %i, Emission Detection: %s\" % (i, val), weight = \"bold\", size = 20)\n",
    "            plt.plot(w, f, color = \"darkblue\")\n",
    "            plt.plot(w, g(w), c = \"orchid\", label = \"FIT\")\n",
    "            plt.axvline(halpha, color = \"tomato\", label = \"Rest Position\")\n",
    "            plt.axvline(g.mean_0.value, color = \"black\", label = \"Measured Position\")\n",
    "            plt.legend(loc = \"lower right\", prop = {\"size\":20})\n",
    "            plt.tick_params(\"both\", labelsize = 15)\n",
    "            plt.savefig(\"/Users/linaflorez/Desktop/UT_TAURUS/Plots/H_ALPHA_FITS/HAlpha_%i.pdf\" % (i))\n",
    "            plt.show()\n",
    "            \n",
    "            ################################################################\n",
    "            #### CALCULATION DOPPLER VELOCITY\n",
    "            ################################################################\n",
    "            absorption_line_mean = g.mean_0.value\n",
    "            emission_line_mean = g.mean_3.value\n",
    "\n",
    "            shift_a = (absorption_line_mean - halpha)\n",
    "            dv_a[i] = c * (shift_a / halpha)\n",
    "\n",
    "            shift_e = (emission_line_mean - halpha)\n",
    "            dv_e[i] = c * (shift_e / halpha)\n",
    "        \n",
    "        \n",
    "        ################################################################\n",
    "        #### IF THERE ARE NOOOOOOOOO EMISSION LINES\n",
    "        ################################################################\n",
    "        else:\n",
    "            ################################################################\n",
    "            #### MAKING THE MODEL\n",
    "            ################################################################\n",
    "            g1 = models.Gaussian1D(-absorption_amplitude, absorption_mean,0.5) #narrowest portion \n",
    "            g2 = models.Gaussian1D(-0.3, absorption_mean,5) #broader portion \n",
    "            g3 = models.Gaussian1D(-0.2, absorption_mean,30) #widest portion \n",
    "            model = g1 + g2 + g3 + models.Const1D(1)\n",
    "            \n",
    "            model.mean_0.tied = tied_function\n",
    "            model.mean_2.tied = tied_function\n",
    "            model.stddev_0.fixed = True\n",
    "            model.stddev_1.fixed = True\n",
    "            model.stddev_2.fixed = True\n",
    "            \n",
    "            fit = fitting.LevMarLSQFitter()\n",
    "            g = fit(model, w, f, maxiter=1000000, weights = 1/e)\n",
    "            \n",
    "            ################################################################\n",
    "            #### CHECKING THE EFFICACY OF THE FITS\n",
    "            ################################################################\n",
    "            plt.style.use(\"seaborn\")\n",
    "            plt.figure(num=None, figsize=(15, 9),facecolor='w', edgecolor='k')\n",
    "            plt.title(\"From File Number: %i, Emission Detection: %s\" % (i, val), weight = \"bold\", size = 20)\n",
    "            plt.plot(w, f, color = \"darkblue\")\n",
    "            plt.plot(w, g(w), c = \"orchid\", label = \"FIT\")\n",
    "            plt.axvline(halpha, color = \"tomato\", label = \"Rest Position\")\n",
    "            plt.axvline(g.mean_1.value, color = \"black\", label = \"Measured Position\")\n",
    "            plt.legend(loc = \"lower right\", prop = {\"size\":20})\n",
    "            plt.tick_params(\"both\", labelsize = 15)\n",
    "            plt.savefig(\"/Users/linaflorez/Desktop/UT_TAURUS/Plots/H_ALPHA_FITS/HAlpha_%i.pdf\" % (i))\n",
    "\n",
    "            plt.show()\n",
    "            \n",
    "            ################################################################\n",
    "            #### CALCULATION DOPPLER VELOCITY\n",
    "            ################################################################\n",
    "            absorption_line_mean = g.mean_0.value\n",
    "            shift = (absorption_line_mean - halpha)\n",
    "            dv_a[i] = c * (shift / halpha)\n",
    "            dv_e[i] = 0 \n",
    "\n",
    "        ###############################################################\n",
    "        ### DETERMINING THE FIT ERROR \n",
    "        ############################################################### \n",
    "        fit_info = fit.fit_info[\"param_cov\"]\n",
    "        print(\"FIT INFO:\", np.shape(fit_info), detections[i])\n",
    "        if fit_info is not None:\n",
    "            fit_error[i] = (np.sqrt(np.diag(fit_info))[2:-1][0])**2 #variance\n",
    "        if fit_info is None:\n",
    "            fit_error[i] = 0\n",
    "    \n",
    "    \n",
    "\n",
    "    fit_df = pd.DataFrame()\n",
    "    fit_df[\"MJD\"] = time\n",
    "    fit_df[\"Absorption -- DV (km/s)\"] = dv_a\n",
    "    fit_df[\"Emission -- DV (km/s)\"] = dv_e\n",
    "    fit_df[\"Fit Error\"] = fit_error\n",
    "    fit_df[\"Detections (based on previous dv measurements)\"] = detections\n",
    "    fit_df[\"File Path\"] = file_path\n",
    "    t = Table.from_pandas(fit_df)\n",
    "    csv_name = input(\"File name for the table?\")\n",
    "    making_table = t.write(\"/Users/linaflorez/Desktop/UT_TAURUS/CSV_FILES/%s\" % (csv_name), format=\"ascii.csv\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NEW DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/linaflorez/Desktop/UT_TAURUS/WDJ114404.76+052951.77/\" #note the / on the end\n",
    "vispath = path + 'VIS_notell/'\n",
    "sp_csv = natsort.natsorted(glob.glob(vispath+'*TAC.csv')) #makes an array containing the path to all csv files. Note the TAC as I didn't want to include the merged spectrum\n",
    "sp_fits = natsort.natsorted(glob.glob(vispath+'*TAC.fits')) #makes an array containing the path to all csv files. Note the TAC as I didn't want to include the merged spectrum\n",
    "#wavelength_range = (6300, 6800)\n",
    "wavelength_range = (6425, 6700)\n",
    "\n",
    "df = pd.read_csv(\"/Users/linaflorez/Desktop/UT_TAURUS/CSV_FILES/OriginalData.csv\")\n",
    "detections = df['Detections']\n",
    "\n",
    "#CSV FILE: OGData_HA.csv\n",
    "\n",
    "fitting_absorption_lines(wavelength_range, sp_csv, sp_fits, detections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/linaflorez/Desktop/UT_TAURUS/\" #note the / on the end\n",
    "#print(os.listdir(path))\n",
    "vispath = path + 'SDSSJ1144_old2/'\n",
    "sp_csv = natsort.natsorted(glob.glob(vispath+'*TAC.csv')) #makes an array containing the path to all csv files. Note the TAC as I didn't want to include the merged spectrum\n",
    "sp_fits = natsort.natsorted(glob.glob(vispath+'*TAC.fits')) #makes an array containing the path to all csv files. Note the TAC as I didn't want to include the merged spectrum\n",
    "#wavelength_range = (6300, 6800)\n",
    "wavelength_range = (6425, 6700)\n",
    "\n",
    "df = pd.read_csv(\"/Users/linaflorez/Desktop/UT_TAURUS/CSV_FILES/NEW_OLD.csv\")\n",
    "detections = df['Detections']\n",
    "\n",
    "#CSV FILE: NEWOLD_HA.csv\n",
    "fitting_absorption_lines(wavelength_range, sp_csv, sp_fits, detections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the LS and Folded Velocity Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_LS_and_fv(list_of_csv):\n",
    "    ###############################################################\n",
    "    ### GETTING DATA\n",
    "    ###############################################################     \n",
    "    calcium_df = pd.concat((pd.read_csv(list_of_csv[0]), pd.read_csv(list_of_csv[1])), axis = 0)\n",
    "    halpha_df = pd.concat((pd.read_csv(list_of_csv[2]), pd.read_csv(list_of_csv[3])), axis = 0)\n",
    "    \n",
    "    ###############################################################\n",
    "    ### SETTING UP PLOT\n",
    "    ############################################################### \n",
    "    plt.style.use(\"seaborn\")\n",
    "    plt.figure(figsize=(8, 8), frameon = True, edgecolor = \"black\")\n",
    "    f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2,figsize=(20,10))\n",
    "\n",
    "    ###############################################################\n",
    "    ### MAKING THE LOMB-SCARGLE\n",
    "    ############################################################### \n",
    "    decision = input(\"Period From Calcium Lines or H\\u03B1 Line? \")\n",
    "    if decision == \"Calcium Lines\":\n",
    "        data = calcium_df.loc[calcium_df['Detections'] == 'Yes']\n",
    "        t, y, dy = data[\"MJD\"], data[\"Weighted Mean\"], data[\"Weighted Error\"]\n",
    "        frequency, power = LS(t, y, dy, normalization= \"model\").autopower(minimum_frequency = 4, maximum_frequency = 12)\n",
    "        period = (1/frequency)\n",
    "        period_value = period[np.argmax(power)]*24\n",
    "        ax1.text(3, 2000,\"Period: %.3f hours\" % (period_value), size = 15)\n",
    "        \n",
    "    else:\n",
    "        data = halpha_df.loc[halpha_df[\"Detections (based on previous dv measurements)\"] == 'Yes']\n",
    "        t, dy = data[\"MJD\"], data[\"Fit Error\"]\n",
    "        y = data[\"Emission -- DV (km/s)\"]\n",
    "#         y = data[\"Absorption -- DV (km/s)\"]\n",
    "        frequency, power = LS(t, y, dy, normalization= \"model\").autopower(minimum_frequency = 4, maximum_frequency = 12)\n",
    "        period = (1/frequency)\n",
    "        period_value = period[np.argmax(power)]*24\n",
    "        ax1.text(3, 15,\"Period: %.3f hours\" % (period_value), size = 15)\n",
    "\n",
    "\n",
    "    ax1.plot(period * 24, power, color = \"darkblue\", label = \"Lomb Scargle\")\n",
    "    ax1.set_xlabel(\"Period (hours)\", weight = \"bold\", size = 15)\n",
    "    ax1.set_ylabel(\"Lomb-Scargle Power\", weight = \"bold\", size = 15)\n",
    "    ax1.set_xlim(2,6)\n",
    "    ax1.tick_params(\"both\", labelsize = 15)\n",
    "    ######################################################################################################## \n",
    "    \n",
    "    ###############################################################\n",
    "    ### MAKING THE TIME V VEL PLOT\n",
    "    ############################################################### \n",
    "    time = ((halpha_df[\"MJD\"].values * u.day).to(u.hour)).value\n",
    "    dv_a, dv_e = halpha_df[\"Absorption -- DV (km/s)\"], halpha_df[\"Emission -- DV (km/s)\"]\n",
    "    \n",
    "    ax2.scatter(time, dv_a, color = \"darkblue\", s = 50, label = \"Absorption\")\n",
    "    ax2.scatter(time, dv_e, color = \"darkcyan\", s = 50, label = \"Emission\")\n",
    "    ax2.set_xlabel(\"Time (Hour)\", weight = \"bold\", size = 20)\n",
    "    ax2.set_ylabel(\"Velocity (km/s)\", weight = \"bold\", size = 20)\n",
    "    ax2.set_xlim(1.406447e6,1.406457e6)\n",
    "    ax2.legend(loc = \"best\", prop = {\"size\":15})\n",
    "    ax2.tick_params(\"both\", labelsize = 15)\n",
    "\n",
    "    ######################################################################################################## \n",
    "    \n",
    "    ###############################################################\n",
    "    ### MAKING FOLDED VELOCITY PLOT\n",
    "    ############################################################### \n",
    "    #EMISSION DETECTED\n",
    "    ca_emission_detected = calcium_df.loc[calcium_df['Detections'] == \"Yes\"]\n",
    "    ca_emission_filepath = ca_emission_detected[\"File Path\"]\n",
    "    ca_emission_detected_x = ((ca_emission_detected[\"MJD\"].values)/(1/(frequency[np.argmax(power)]))) %1\n",
    "    ca_emission_detected_x = np.append(ca_emission_detected_x,ca_emission_detected_x+1)\n",
    "    ca_emission_detected_y = ca_emission_detected[\"Weighted Mean\"]\n",
    "    ca_emission_detected_y = np.tile(ca_emission_detected_y,2)\n",
    "    \n",
    "    ha_emission_detected = halpha_df.loc[halpha_df[\"Detections (based on previous dv measurements)\"] == \"Yes\"]\n",
    "    ha_emission_filepath = ha_emission_detected[\"File Path\"]\n",
    "    ha_emission_detected_x = ((ha_emission_detected[\"MJD\"].values)/(1/(frequency[np.argmax(power)]))) %1\n",
    "    ha_emission_detected_x = np.append(ha_emission_detected_x,ha_emission_detected_x+1)\n",
    "    ha_emission_detected_y = ha_emission_detected[\"Emission -- DV (km/s)\"]\n",
    "    ha_emission_detected_y = np.tile(ha_emission_detected_y,2)\n",
    "    \n",
    "    ha_absorption_detected = halpha_df.loc[halpha_df[\"Detections (based on previous dv measurements)\"] == \"Yes\"]\n",
    "    ha_absorption_filepath = ha_absorption_detected[\"File Path\"]\n",
    "    ha_absorption_detected_x = ((ha_absorption_detected[\"MJD\"].values)/(1/(frequency[np.argmax(power)]))) %1\n",
    "    ha_absorption_detected_x = np.append(ha_absorption_detected_x,ha_absorption_detected_x+1)\n",
    "    ha_absorption_detected_y = ha_absorption_detected[\"Absorption -- DV (km/s)\"]\n",
    "    ha_absorption_detected_y = np.tile(ha_absorption_detected_y,2)\n",
    "    \n",
    "    ###############################################################\n",
    "    #NO EMISSION DETECTED\n",
    "    ca_no_emission_detected = calcium_df.loc[calcium_df['Detections'] == \"No\"]\n",
    "    ca_no_emission_filepath = ca_no_emission_detected[\"File Path\"]\n",
    "    ca_no_emission_detected_x = ((ca_no_emission_detected[\"MJD\"].values)/(1/(frequency[np.argmax(power)]))) %1\n",
    "    ca_no_emission_detected_x = np.append(ca_no_emission_detected_x,ca_no_emission_detected_x+1)\n",
    "    ca_no_emission_detected_y = ca_no_emission_detected[\"Weighted Mean\"]\n",
    "    ca_no_emission_detected_y = np.tile(ca_no_emission_detected_y,2)\n",
    "    \n",
    "    ha_no_emission_detected = halpha_df.loc[halpha_df[\"Detections (based on previous dv measurements)\"] == \"No\"]\n",
    "    ha_no_emission_filepath = ha_no_emission_detected[\"File Path\"]\n",
    "    ha_no_emission_detected_x = ((ha_no_emission_detected[\"MJD\"].values)/(1/(frequency[np.argmax(power)]))) %1\n",
    "    ha_no_emission_detected_x = np.append(ha_no_emission_detected_x,ha_no_emission_detected_x+1)\n",
    "    ha_no_emission_detected_y = ha_no_emission_detected[\"Emission -- DV (km/s)\"]\n",
    "    ha_no_emission_detected_y = np.tile(ha_no_emission_detected_y,2)\n",
    "    \n",
    "    ha_no_absorption_detected = halpha_df.loc[halpha_df[\"Detections (based on previous dv measurements)\"] == \"No\"]\n",
    "    ha_no_absorption_filepath = ha_no_absorption_detected[\"File Path\"]\n",
    "    ha_no_absorption_detected_x = ((ha_no_absorption_detected[\"MJD\"].values)/(1/(frequency[np.argmax(power)]))) %1\n",
    "    ha_no_absorption_detected_x = np.append(ha_no_absorption_detected_x,ha_no_absorption_detected_x+1)\n",
    "    ha_no_absorption_detected_y = ha_no_absorption_detected[\"Absorption -- DV (km/s)\"]\n",
    "    ha_no_absorption_detected_y = np.tile(ha_no_absorption_detected_y,2)\n",
    "\n",
    "    ###############################################################\n",
    "    #PLOTTING FOLDED VELOCITY\n",
    "    ax3.scatter(ca_emission_detected_x, ca_emission_detected_y, color = \"dodgerblue\")\n",
    "    ax3.scatter(ha_absorption_detected_x, ha_absorption_detected_y, color = \"darkolivegreen\")\n",
    "    ax3.scatter(ha_no_absorption_detected_x, ha_no_absorption_detected_y, color = \"darkolivegreen\")\n",
    "    ax3.tick_params(\"both\", labelsize = 15)\n",
    "    ax3.set_xlabel(\"Orbital Phase\", weight = \"bold\", size = 15)\n",
    "    ax3.set_ylabel(\"Velocity (kms$^{-1}$)\", weight = \"bold\", size = 15)\n",
    "\n",
    "    ######################################################################################################## \n",
    "    \n",
    "    ###############################################################\n",
    "    ### MAKING FOLDED VELOCITY PLOT ACROSS 3 DAYS\n",
    "    ############################################################### \n",
    "    mjds = np.concatenate([np.tile(ca_emission_detected[\"MJD\"],2), np.tile(ha_absorption_detected[\"MJD\"],2), \\\n",
    "                           np.tile(ha_no_absorption_detected[\"MJD\"],2)], axis = 0)\n",
    "    xs = np.concatenate([ca_emission_detected_x, ha_absorption_detected_x, ha_no_absorption_detected_x], axis = 0)\n",
    "    ys = np.concatenate([ca_emission_detected_y, ha_absorption_detected_y, ha_no_absorption_detected_y], axis = 0)\n",
    "    xs = np.concatenate([ca_emission_detected_x, ha_absorption_detected_x, ha_no_absorption_detected_x], axis = 0)\n",
    "    ys = np.concatenate([ca_emission_detected_y, ha_absorption_detected_y, ha_no_absorption_detected_y], axis = 0)\n",
    "    t = Table([mjds, xs, ys], names=('MJD', 'PHASE', 'VELOCITY'), dtype=('f4', 'f4', 'f4'))\n",
    "\n",
    "    day_one = []\n",
    "    day_two = []\n",
    "    day_three = []\n",
    "    for i in range(len(mjds)):\n",
    "        if math.modf(mjds[i])[1] == 58168.0:\n",
    "            day_one.append(i)\n",
    "        if math.modf(mjds[i])[1] == 58601.0:\n",
    "            day_two.append(i)\n",
    "        if math.modf(mjds[i])[1] == 58602.0:\n",
    "            day_three.append(i)\n",
    "\n",
    "    ax4.scatter(xs[day_one], ys[day_one], color = \"orange\", label = \"Day One\")\n",
    "    ax4.scatter(xs[day_two], ys[day_two], color = \"brown\",  label = \"Day Two\")\n",
    "    ax4.scatter(xs[day_three], ys[day_three], color = \"mediumorchid\", label = \"Day Three\")\n",
    "    ax4.legend(loc = \"best\", prop = {\"size\":15})\n",
    "    ax4.tick_params(\"both\", labelsize = 15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CA_CSV_OLD = \"/Users/linaflorez/Desktop/Summer2019/CSV_FILES/NEW_OLD.csv\"\n",
    "CA_CSV_RECENT = \"/Users/linaflorez/Desktop/Summer2019/CSV_FILES/OriginalData.csv\"\n",
    "HA_CSV_OLD = \"/Users/linaflorez/Desktop/Summer2019/CSV_FILES/NEWOLD_HA.csv\"\n",
    "HA_CSV_RECENT = \"/Users/linaflorez/Desktop/Summer2019/CSV_FILES/OGData_HA.csv\"\n",
    "\n",
    "list_of_data = (CA_CSV_OLD,CA_CSV_RECENT, HA_CSV_OLD, HA_CSV_RECENT)\n",
    "\n",
    "making_LS_and_fv(list_of_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
